from dataclasses import fields
from pathlib import Path
import torch
import torch.nn as nn
import imageio
import os
import numpy as np

from image_generation_gan_arch.data_types import TrainingParams


def create_directories(parent_path: Path, training_params: TrainingParams) -> None:
    checkpoint_dir_path = parent_path / training_params.checkpoint_dir

    if not os.path.exists(checkpoint_dir_path):
        os.makedirs(checkpoint_dir_path)

    sample_dir_path = parent_path / training_params.sample_dir
    if not os.path.exists(sample_dir_path):
        os.makedirs(sample_dir_path)


def model_checkpoint(
    iteration: int, training_params: TrainingParams, models: dict[str, nn.Module]
) -> None:
    parent_path = Path(__file__).parent.parent

    for model_name, model in models.items():
        model_path = (
            parent_path
            / training_params.checkpoint_dir
            / f"{model_name}_{iteration}.pkl"
        )
        torch.save(model.state_dict(), model_path)


def merge_images(
    sources: torch.Tensor, targets: torch.Tensor, training_params: TrainingParams
) -> np.ndarray:
    """Creates a grid consisting of pairs of columns, where the first column in
    each pair contains images source images and the second column in each pair
    contains images generated by the CycleGAN from the corresponding images in
    the first column.
    """
    _, _, h, w = sources.shape
    row = int(np.sqrt(training_params.batch_size))
    merged = np.zeros([3, row * h, row * w * 2])
    for idx, s, t in zip(
        range(row**2),
        sources,
        targets,
    ):
        i = idx // row
        j = idx % row
        merged[:, i * h : (i + 1) * h, (j * 2) * h : (j * 2 + 1) * h] = s
        merged[:, i * h : (i + 1) * h, (j * 2 + 1) * h : (j * 2 + 2) * h] = t
    return merged.transpose(1, 2, 0)


def create_image_grid(array: np.ndarray, ncols: int | None = None) -> np.ndarray:
    """ """
    num_images, channels, cell_h, cell_w = array.shape
    if not ncols:
        ncols = int(np.sqrt(num_images))
    nrows = int(np.floor(num_images / float(ncols)))
    result = np.zeros((cell_h * nrows, cell_w * ncols, channels), dtype=array.dtype)
    for i in range(0, nrows):
        for j in range(0, ncols):
            result[i * cell_h : (i + 1) * cell_h, j * cell_w : (j + 1) * cell_w, :] = (
                array[i * ncols + j].transpose(1, 2, 0)
            )

    if channels == 1:
        result = result.squeeze()
    return result


def gan_save_samples(
    G: nn.Module,
    fixed_noise: torch.Tensor,
    iteration: int,
    training_params: TrainingParams,
    device: torch.tensor,
) -> None:
    generated_images = G(fixed_noise)
    generated_images = to_data(generated_images, device=device)

    grid = create_image_grid(generated_images)

    path = (
        Path(__file__).parent.parent
        / training_params.sample_dir
        / "sample-{:06d}.png".format(iteration)
    )
    image_array_uint8 = (grid * 255).astype(np.uint8)
    imageio.imwrite(path, image_array_uint8)
    print("Saved {}".format(path))


def to_data(x: torch.Tensor, device: torch.device) -> np.ndarray:
    """Converts variable to numpy."""
    if device.type == "mps" or device.type == "cuda":
        x = x.cpu()
    return x.data.numpy()


def cyclegan_save_samples(
    iteration: int,
    fixed_Y: torch.Tensor,
    fixed_X: torch.Tensor,
    G_YtoX: nn.Module,
    G_XtoY: nn.Module,
    training_params: TrainingParams,
    device: torch.device,
) -> None:
    """Saves samples from both generators X->Y and Y->X."""
    fake_X = G_YtoX(fixed_Y)
    fake_Y = G_XtoY(fixed_X)

    X, fake_X = to_data(fixed_X, device=device), to_data(fake_X, device=device)
    Y, fake_Y = to_data(fixed_Y, device=device), to_data(fake_Y, device=device)

    merged = merge_images(X, fake_Y, training_params)

    path = (
        Path(__file__).parent.parent
        / training_params.sample_dir
        / "sample-{:06d}-X-Y.png".format(iteration)
    )

    image_array_uint8 = (merged * 255).astype(np.uint8)
    imageio.imwrite(path, image_array_uint8)
    print("Saved {}".format(path))

    merged = merge_images(Y, fake_X, training_params)

    path = (
        Path(__file__).parent.parent
        / training_params.sample_dir
        / "sample-{:06d}-Y-X.png".format(iteration)
    )

    image_array_uint8 = (merged * 255).astype(np.uint8)
    imageio.imwrite(path, image_array_uint8)
    print("Saved {}".format(path))


def print_models(
    G_XtoY: nn.Module, G_YtoX: nn.Module, D_X: nn.Module, D_Y: nn.Module
) -> None:
    """Prints model information for the generators and discriminators."""
    if G_YtoX:
        print("                 G_XtoY                ")
        print("---------------------------------------")
        print(G_XtoY)
        print("---------------------------------------")

        print("                 G_YtoX                ")
        print("---------------------------------------")
        print(G_YtoX)
        print("---------------------------------------")

        print("                  D_X                  ")
        print("---------------------------------------")
        print(D_X)
        print("---------------------------------------")

        print("                  D_Y                  ")
        print("---------------------------------------")
        print(D_Y)
        print("---------------------------------------")
    else:
        print("                 G                     ")
        print("---------------------------------------")
        print(G_XtoY)
        print("---------------------------------------")

        print("                  D                    ")
        print("---------------------------------------")
        print(D_X)
        print("---------------------------------------")


def print_opts(training_params: TrainingParams) -> None:
    """Prints the values of all command-line arguments."""
    print("=" * 80)
    print("Training Parameters".center(80))
    print("-" * 80)
    for field in fields(training_params):
        print(f"{field.name}: {getattr(training_params, field.name)}".center(80))
    print("=" * 80)


def sample_noise(batch_size: int, dim: int, device: torch.device) -> torch.Tensor:
    """
    Generate a PyTorch Tensor of uniform random noise.

    Input:
    - batch_size: Integer giving the batch size of noise to generate.
    - dim: Integer giving the dimension of noise to generate.

    Output:
    - A PyTorch Tensor of shape (batch_size, dim, 1, 1) containing uniform
      random noise in the range (-1, 1).
    """
    return (torch.rand(batch_size, dim) * 2 - 1).to(device).unsqueeze(2).unsqueeze(3)
